{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787ac091",
   "metadata": {},
   "source": [
    "## **Agent Memory with Redis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb6c423",
   "metadata": {},
   "source": [
    "### **I. Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c0379f",
   "metadata": {},
   "source": [
    "Without memory, AI agents are like goldfish - they forget everything after each conversation and can't learn from past interactions or maintain context across sessions. Agentic systems require both **short-term** and **long-term** memory in order to complete tasks in a personalized and resilient manner. Memory is all about state management and `Redis` is the well-known in-memory database for exactly this kind of use case today in production systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617994f5",
   "metadata": {},
   "source": [
    "### **II. What we'll build**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef17ea",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to build a **memory-enabled travel agent** with **Redis and LangGraph** that remembers user preferences and provides personalized recommendations. This is a horizontal concept that you can take and apply to your own agent use cases.\n",
    "\n",
    "We'll explore:\n",
    "1. Short-term memory management using LangGraph's checkpointer\n",
    "2. Long-term memory storage and retrieval using RedisVL\n",
    "3. Managing long-term memory as a tool for a ReAct agent\n",
    "4. Managing conversation history size with summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c44b9",
   "metadata": {},
   "source": [
    "### **III. Memory architecture overview**\n",
    "\n",
    "Ouer agent uses a dual-memory system:\n",
    "* **Short-term**: Manages conversation context\n",
    "* **Long-term**: Stores persistent knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac802d5d",
   "metadata": {},
   "source": [
    "#### **1. Short-term Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d1e34",
   "metadata": {},
   "source": [
    "The agent tracks chat history using Redis through LangGraph's checkpointer. Each node in the graph (Retrieve Memories, Respond, Summarize) saves its state to Redis, including conversation history and thread metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96208d83",
   "metadata": {},
   "source": [
    "<img src=\"short-term-memory.png\" alt=\"alt text\" width=\"400px\" height=\"400px\" style=\"background-color: lightblue;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846e7c1",
   "metadata": {},
   "source": [
    "To prevent context window pollution, the agent summarizes conversations when they exceed a configurable length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d5b81d",
   "metadata": {},
   "source": [
    "#### **2. Long-term Memory**\n",
    "\n",
    "Long-term memories are stored & indexed in Redis using the RedisVL client, with 2 types:\n",
    "* **Episodic**: User preferences and experiences\n",
    "* **Semantic**: General travel knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594b3b7",
   "metadata": {},
   "source": [
    "<img src=\"long-term-memory.png\" alt=\"alt text\" width=\"500px\" height=\"300px\" style=\"background-color: lightblue;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058a3722",
   "metadata": {},
   "source": [
    "### **IV. Set up enviroment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c977d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m145 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m142 packages\u001b[0m \u001b[2min 58ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add langchain-google-genai langgraph-checkpoint langgraph langgraph-checkpoint-redis langchain-redis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b937f7e4",
   "metadata": {},
   "source": [
    "#### **1. Required API keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aff84850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(key: str):\n",
    "    if key not in os.environ:\n",
    "        os.environ[key] = getpass.getpass(f\"Enter your {key}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e0984",
   "metadata": {},
   "source": [
    "#### **2. Setup Redis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a768fb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from redis import Redis\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "redis_host = os.getenv(\"REDIS_HOST\")\n",
    "redis_port = os.getenv(\"REDIS_PORT\")\n",
    "redis_username = os.getenv(\"REDIS_USERNAME\")\n",
    "redis_password = os.getenv(\"REDIS_PASSWORD\")\n",
    "\n",
    "redis_client = Redis(\n",
    "    host = redis_host,\n",
    "    port = 13475,\n",
    "    decode_responses = True,\n",
    "    username = redis_username,\n",
    "    password = redis_password\n",
    ")\n",
    "\n",
    "redis_client.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5f9a8",
   "metadata": {},
   "source": [
    "#### **3. Prepare memory data models**\n",
    "\n",
    "In this section, we'll create a robust data modeling system for our agent's memory using `Pydantic`. These models will ensure type safety and provide clear data strutures for storing and retrieving memories form Redis.\n",
    "\n",
    "We'll implement 4 key components:\n",
    "1. `MemoryType` - An enumeration that categorizes memories into 2 types:\n",
    "* Episodic: Personal experiences and user preferences\n",
    "* Semantic: General knowledge and domain facts\n",
    "2. `Memory` - The core model representing a single memory entry with its content and metadata\n",
    "3. `Memories` - A container model that holds collections of memory objects\n",
    "4. `StoredMemory` - A specialized model for memories that have been persistend to Redis\n",
    "\n",
    "These models work together to create a complete memory lifecycle, from creation to storage and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c97d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ulid\n",
    "\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c68805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryType(str, Enum):\n",
    "    \"\"\"\n",
    "    Defines the type of long-term memory for categorization and retrieval.\n",
    "\n",
    "    EPISODIC: Personal experiences and user-specific preferences\n",
    "            (e.g., \"User prefers Delta airlines\", \"User visited Paris last year\")\n",
    "    \n",
    "    SEMANTIC: General domain knowledge and facts\n",
    "            (e.g., \"Singapore requires passport\", \"Tokyo has excellent public transit\")\n",
    "\n",
    "    The type of a long-term memory.\n",
    "\n",
    "    EPISODIC: User specific experiences and preferences\n",
    "\n",
    "    SEMANTIC: General on top of the user's preferences and LLM's training data.\n",
    "    \"\"\"\n",
    "\n",
    "    EPISODIC = \"episodic\"\n",
    "    SEMANTIC = \"semantic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a538773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(BaseModel):\n",
    "    \"\"\"Represents a single long-term memory.\"\"\"\n",
    "\n",
    "    content: str\n",
    "    memory_type: MemoryType\n",
    "    metadata: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1cc2eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memories(BaseModel):\n",
    "    \"\"\"A list of memories extracted from a conversation by an LLM.\"\"\"\n",
    "\n",
    "    memories: List[Memory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "857719f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoredMemory(Memory):\n",
    "    \"\"\"A stored long-term memory\"\"\"\n",
    "\n",
    "    id: str # The redis key\n",
    "    memory_id: ulid.ULID = Field(default_factory=lambda: ulid.ULID())\n",
    "    create_at: datetime = Field(default_factory=datetime.now)\n",
    "    user_id: Optional[str] = None\n",
    "    thread_id: Optional[str] = None\n",
    "    memory_type: Optional[MemoryType] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6756fd",
   "metadata": {},
   "source": [
    "Now we have type-safe data models that handle the complete memory lifecycle from LLM extraction to Redis storage, with proper metadata tracking for production use. Next, we'll set up the Redis infrastructure to store and search these memories using vector embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398f4b8",
   "metadata": {},
   "source": [
    "### **V. Memory Storage**\n",
    "\n",
    "- **Short-term memory** is handled automatically by `RedisSaver` from `langgraph-checkpoint-redis`\n",
    "- **Long-term memory**, we'll use RedisVL with vector embeddings to enable semantic search of past experiences and knowledge.\n",
    "\n",
    "Below, we'll create a search index schema in Redis to hold our long term memories. The schema has a few different fields including content, memory type, metadata, timestamps, user id, memory id, and the embedding of the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a35893a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.index import SearchIndex\n",
    "from redisvl.schema.schema import IndexSchema\n",
    "\n",
    "# Define the schema for our vector search index\n",
    "# This creates the structure for storing and query memories\n",
    "memory_schema = IndexSchema.from_dict({\n",
    "    \"index\": {\n",
    "        \"name\": \"agent_memories\", # Index name for identification\n",
    "        \"prefix\": \"memory\", # Redis key prefix (memory:1, memory:2, ...)\n",
    "        \"key_separator\": \":\",\n",
    "        \"storage_type\": \"json\"\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {\"name\": \"content\", \"type\": \"text\"},\n",
    "        {\"name\": \"memory_type\", \"type\": \"tag\"},\n",
    "        {\"name\": \"metadata\", \"type\": \"text\"},\n",
    "        {\"name\": \"create_at\", \"type\": \"text\"},\n",
    "        {\"name\": \"user_id\", \"type\": \"tag\"},\n",
    "        {\"name\": \"memory_id\", \"type\": \"tag\"},\n",
    "        {\n",
    "            \"name\": \"embedding\", \n",
    "            \"type\": \"vector\",\n",
    "            \"attrs\": {\n",
    "                \"algorithm\": \"flat\",\n",
    "                \"dims\": 768,\n",
    "                \"distance_metric\": \"cosine\",\n",
    "                \"datatype\": \"float32\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc401701",
   "metadata": {},
   "source": [
    "Below we create the `SearchIndex` from the `IndexSchema` and our Redis client connection object. We'll overwrite the index spec if its already created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19220e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long-term memory index ready\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    long_term_memory_index = SearchIndex(\n",
    "        schema = memory_schema,\n",
    "        redis_client = redis_client,\n",
    "        validate_on_load = True\n",
    "    )\n",
    "\n",
    "    long_term_memory_index.create(overwrite = True)\n",
    "    print(\"Long-term memory index ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f431fb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Index Information:\n",
      "╭────────────────┬────────────────┬────────────────┬────────────────┬────────────────╮\n",
      "│ Index Name     │ Storage Type   │ Prefixes       │ Index Options  │ Indexing       │\n",
      "├────────────────┼────────────────┼────────────────┼────────────────┼────────────────┤\n",
      "| agent_memories | JSON           | ['memory']     | []             | 0              |\n",
      "╰────────────────┴────────────────┴────────────────┴────────────────┴────────────────╯\n",
      "Index Fields:\n",
      "╭─────────────────┬─────────────────┬─────────────────┬─────────────────┬─────────────────┬─────────────────┬─────────────────┬─────────────────┬─────────────────┬─────────────────┬─────────────────╮\n",
      "│ Name            │ Attribute       │ Type            │ Field Option    │ Option Value    │ Field Option    │ Option Value    │ Field Option    │ Option Value    │ Field Option    │ Option Value    │\n",
      "├─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┼─────────────────┤\n",
      "│ $.content       │ content         │ TEXT            │ WEIGHT          │ 1               │                 │                 │                 │                 │                 │                 │\n",
      "│ $.memory_type   │ memory_type     │ TAG             │ SEPARATOR       │ ,               │                 │                 │                 │                 │                 │                 │\n",
      "│ $.metadata      │ metadata        │ TEXT            │ WEIGHT          │ 1               │                 │                 │                 │                 │                 │                 │\n",
      "│ $.create_at     │ create_at       │ TEXT            │ WEIGHT          │ 1               │                 │                 │                 │                 │                 │                 │\n",
      "│ $.user_id       │ user_id         │ TAG             │ SEPARATOR       │ ,               │                 │                 │                 │                 │                 │                 │\n",
      "│ $.memory_id     │ memory_id       │ TAG             │ SEPARATOR       │ ,               │                 │                 │                 │                 │                 │                 │\n",
      "│ $.embedding     │ embedding       │ VECTOR          │ algorithm       │ FLAT            │ data_type       │ FLOAT32         │ dim             │ 768             │ distance_metric │ COSINE          │\n",
      "╰─────────────────┴─────────────────┴─────────────────┴─────────────────┴─────────────────┴─────────────────┴─────────────────┴─────────────────┴─────────────────┴─────────────────┴─────────────────╯\n"
     ]
    }
   ],
   "source": [
    "!rvl index info -i agent_memories -u \"redis://default:5xna2u8da0hRpu1lGglkMpN6cpMv89vg@redis-13475.crce178.ap-east-1-1.ec2.redns.redis-cloud.com:13475\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b127a137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:57:05 [RedisVL] INFO   Indices:\n",
      "17:57:05 [RedisVL] INFO   1. agent_memories\n"
     ]
    }
   ],
   "source": [
    "!rvl index listall -u \"redis://default:5xna2u8da0hRpu1lGglkMpN6cpMv89vg@redis-13475.crce178.ap-east-1-1.ec2.redns.redis-cloud.com:13475\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45003a",
   "metadata": {},
   "source": [
    "#### **1. Functions to access memories**\n",
    "\n",
    "Next, we provide 3 core functions to access, store and retrieve memories. We'll eventually use these in tools for the LLM to call. We'll start by loading a vectorizer class to create GEMINI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87fc68db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'redisvl.utils.vectorize.text.gemini'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mredisvl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorize\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgemini\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeminiTextVectorizer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'redisvl.utils.vectorize.text.gemini'"
     ]
    }
   ],
   "source": [
    "from redisvl.utils.vectorize.text.gemini import GeminiTextVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6efe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
