{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87e2336",
   "metadata": {},
   "source": [
    "## **Build a Web Research Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb564e0",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29a58f",
   "metadata": {},
   "source": [
    "In the previous excercise, you learned the basics of the Tavily API. Now, let's take it a step further: we'll combine that knowledge with LLMs to unlock real value. In this tutorial, you'll learn how to build a web research agent that can search, extract, crawl and reason over live web data.\n",
    "\n",
    "You already explored the various parameter configurations available for each Tavily API endpoint. With the official `Tavily-LangChain integration`, our agent can automatically set these parameters - like `time_range` for search or specific crawl `instructions` - based on the context and requirements of each task. This dynamic, LLM-powered configuration is powerful in agentic systems.\n",
    "\n",
    "By the end of this lesson, you'll know how to:\n",
    "- Seamlessly connect foundation models to the web for up-to-date research\n",
    "- Build a react-style web agent\n",
    "- Dynamically configure search, extract and crawl parameters the Tavily-LangChain integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7faba",
   "metadata": {},
   "source": [
    "### **Getting Started** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808d6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install -U tavily-python langchain-google-genai langchain langchain-tavily langgraph python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e60cbdf",
   "metadata": {},
   "source": [
    "### **Setting Up Tavily Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f14aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup succesfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "gg_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if tavily_api_key is None or gg_api_key is None:\n",
    "    print(\"Please set API Key\")\n",
    "else:\n",
    "    tavily_client = TavilyClient(api_key=tavily_api_key)\n",
    "    print(\"Setup succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5169bcbb",
   "metadata": {},
   "source": [
    "Let's define the following modular tools with the Tavily-LangChain integration:\n",
    "1. **Search** the web for relevant information\n",
    "2. **Extract** content from specific web pages\n",
    "3. **Crawl** entire websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539f28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the set of web tools our agent will use to interact with the Tavily API\n",
    "from langchain_tavily import TavilySearch, TavilyCrawl, TavilyExtract\n",
    "\n",
    "search = TavilySearch(max_results=5, topic=\"general\")\n",
    "extract = TavilyExtract(extract_depth=\"advanced\")\n",
    "crawl = TavilyCrawl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227fbd8d",
   "metadata": {},
   "source": [
    "Initialize the LLM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7545d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing well, thank you for asking!\n",
      "\n",
      "How are you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    api_key = gg_api_key\n",
    ")\n",
    "\n",
    "# test setup\n",
    "response = llm.invoke(\"Hi, how are you?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafb442",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
