{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0484b94",
   "metadata": {},
   "source": [
    "## **Search, Extract and Crawl the Web**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99078f9f",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4afb83f",
   "metadata": {},
   "source": [
    "In this tutorial, you'll gain hands-on experience with the core capabilities of the Tavily API - searching the web with semantic understanding, extracting content from live web pages, and crawling entire websites.\n",
    "\n",
    "These skills are essential for anyone building AI agents or applications that need up-to-date, relevant information from the internet. By learning how to programmatically access and process real-time web data, you'll able to bridge the gap between static language models and the dynamic world they operate in, making your agents smarter, more accurate and context-aware.\n",
    "\n",
    "We'll cover:\n",
    "- How to perform web searches and retrieve the most relevant results\n",
    "- How to extract clean, usable content from any URL\n",
    "- How to crawl websites to gather comprehensive information\n",
    "- How to fine-tune your queries with advanced parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d46e32",
   "metadata": {},
   "source": [
    "### **Getting Started**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f988f7",
   "metadata": {},
   "source": [
    "1. **Sign up** for Tavily at `app.tavily.com` to get API key.\n",
    "2. **Copy API key** and paste to .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3006069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -q -q python-dotenv tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6094dce",
   "metadata": {},
   "source": [
    "### **Setting up Tavily Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0121e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tavily client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "if tavily_api_key:\n",
    "    tavily_client = TavilyClient(api_key=tavily_api_key)\n",
    "    print(\"Tavily client initialized successfully.\")\n",
    "else: \n",
    "    print(\"Please set the TAVILY_API_KEY environment variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725516c4",
   "metadata": {},
   "source": [
    "### **Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1074f8",
   "metadata": {},
   "source": [
    "Let's run a basic web search query to retrieve up-to-date information about NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = tavily_client.search(\n",
    "    query=\"What happend in NYC today?\", \n",
    "    max_results=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ecb7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://abc7ny.com/news/', 'title': 'Breaking News | Eyewitness News Feed - ABC7 New York', 'content': 'The massive fire has completely destroyed at least six businesses along Maple Avenue, between Winans and Conklin avenues, according to officials. Eyewitness', 'score': 0.50769037, 'raw_content': None}\n",
      "{'url': 'https://www.cbsnews.com/newyork/local-news/new-york/', 'title': 'New York News', 'content': \"High tide brings coastal flooding to parts of Long Island. A nor'easter that's bearing down on the NYC area continues to cause flooding concerns today for Long\", 'score': 0.46497503, 'raw_content': None}\n",
      "{'url': 'https://nypost.com/metro/', 'title': 'Breaking NYC News & Local Headlines | New York Post', 'content': 'Grieving parents sue NYC day care after 1-year-old drowned as caretaker was cooking.', 'score': 0.3831801, 'raw_content': None}\n",
      "dict_keys(['url', 'title', 'content', 'score', 'raw_content'])\n"
     ]
    }
   ],
   "source": [
    "for result in search_results[\"results\"]:\n",
    "    print(result)\n",
    "\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885bfcc",
   "metadata": {},
   "source": [
    "Let's run another search query with specific question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cd84b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = tavily_client.search(\n",
    "    query=\"Anthropic model release?\",\n",
    "    max_results=3,\n",
    "    time_range=\"month\",\n",
    "    include_domains=[\"techcrunch.com\"],\n",
    "    topic=\"news\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78f3e9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘Selling coffee beans to Starbucks’ – how the AI boom could leave AI’s biggest companies behind - TechCrunch\n",
      "https://techcrunch.com/2025/09/14/selling-coffee-beans-to-starbucks-how-the-ai-boom-could-leave-ais-biggest-companies-behind/\n",
      "It might seem like a silly question, but it’s come up a lot in my conversations with AI startups, which are increasingly comfortable with businesses that used to be dismissed as “GPT wrappers,” or companies that build interfaces on top of existing AI models like ChatGPT. Throughout the contemporary boom, the success of AI has been inextricable from the success of the companies building foundation models — specifically, OpenAI, Anthropic, and Google. For years, foundation model development was the only AI business there was — and the fast pace of progress made their lead seem insurmountable. The assumption was that, however AI models ended up making money, the lion’s share of the benefit would flow back to the foundation model companies, who had done the work that was hardest to replicate. AI, Anthropic, foundation models, Google, OpenAI\n",
      "\n",
      "\n",
      "Salesforce launches ‘Missonforce,’ a national security-focused business unit - TechCrunch\n",
      "https://techcrunch.com/2025/09/16/salesforce-launches-missonforce-a-national-security-focused-business-unit/\n",
      "It will be focused on incorporating AI into defense workflows in three main areas: personnel, logistics, and decision making, according to a company press release. This news is the latest in a wave of tech companies building and offering services specifically for the U.S. government. OpenAI launched a version of its ChatGPT designed for U.S. government agencies in January. In August, the company announced it struck a deal with the government to give federal agencies access to its enterprise ChatGPT tier for just $1 a year. AI, AI agents, Anthropic, artificial intelligence, defense, Enterprise, Google, Government & Policy, national security, OpenAI, Salesforce, United States Becca is a senior writer at TechCrunch that covers venture capital trends and startups.\n",
      "\n",
      "\n",
      "Former UK Prime Minister Rishi Sunak to advise Microsoft and Anthropic - TechCrunch\n",
      "https://techcrunch.com/2025/10/10/former-uk-prime-minister-rishi-sunak-to-advise-microsoft-and-anthropic/\n",
      "# Former UK Prime Minister Rishi Sunak to advise Microsoft and Anthropic Rishi Sunak, who served as the United Kingdom’s prime minister from 2022 to 2024, has taken on senior advisory roles as Microsoft and Anthropic, The Guardian reports. Letters from the Parliament’s office of the Advisory Committee on Business Appointments (Acoba) disclosing Sunak’s appointments revealed concerns that the ex-Conservative PM’s privileged information could “grant Microsoft an unfair advantage.” Sunak said he would steer clear on advising on U.K. policy matters, stick to high-level perspectives on macro-economic and geopolitical trends, and avoid lobbying. Techcrunch event AI, Anthropic, Government & Policy, Microsoft, Rishi Sunak Rebecca Bellan is a senior reporter at TechCrunch where she covers the business, policy, and emerging trends shaping artificial intelligence.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in search_results[\"results\"]:\n",
    "    print(result[\"title\"])\n",
    "    print(result[\"url\"])\n",
    "    print(result[\"content\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff3715",
   "metadata": {},
   "source": [
    "### **Extract**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db5957",
   "metadata": {},
   "source": [
    "Next, we'll use the Tavily extract endpoint to retrive the complete content (i.e, `raw_content`) of each page using the URLs from our previous search results. Instead of just using the short content snippets from the search, this allows us to access the full text of each page. For efficiency, the extract endpoint can process up to 20 URLs at once in a single call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b283aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_results = tavily_client.extract(\n",
    "    urls=[result[\"url\"] for result in search_results[\"results\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd655e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "for result in extract_results[\"results\"]:\n",
    "    print(result[\"url\"])\n",
    "    print(result[\"raw_content\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c373cbd3",
   "metadata": {},
   "source": [
    "Rather than using the extract endpoint to return raw page content, we can combine the search and extract endpoints into a API call by using the search endpoint with the `include_raw_content=True` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4196e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = tavily_client.search(\n",
    "    query=\"Anthropic model release?\",\n",
    "    max_results=1,\n",
    "    include_raw_content=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the results\n",
    "for result in search_results[\"results\"]:\n",
    "    print(result[\"url\"])\n",
    "    print(result[\"content\"])\n",
    "    print(result[\"score\"])\n",
    "    print(result[\"raw_content\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be753a4",
   "metadata": {},
   "source": [
    "### Crawl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25230686",
   "metadata": {},
   "source": [
    "Now let's use Tavily to crawl a webpage and extract all its links. Web crawling is the process of automatically navigating through websites by following hyperlinks to discover numerous web pages and URLs (think of it like falling down a Wikipedia rabbit hole - Clinking from page to page, diving deeper into interconnected topics). For autonomous web agents, this capability is essential for accessing deep web data which might be difficult to retrieve via search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795698b5",
   "metadata": {},
   "source": [
    "Let's begin by crawling the Tavily website to gather all nested pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12536714",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_results = tavily_client.crawl(url=\"tavily.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2893daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in crawl_results[\"results\"]:\n",
    "    print(result[\"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a03dfc",
   "metadata": {},
   "source": [
    "If you're interested in just the links (without the full page content), use the Map endpoint. It's a faster and more cost-effective way to retrieve all the links from a site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7905f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_results = tavily_client.map(url=\"tavily.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1195c",
   "metadata": {},
   "source": [
    "The `instructions` parameter of crawl/map endpoint is a powerful feature that lets you guide the web crawl using natural language instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c645b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_map_results = tavily_client.map(\n",
    "    url=\"tavily.com\",\n",
    "    instructions=\"find only the developer docs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9437f5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_url': 'tavily.com',\n",
       " 'results': ['https://docs.tavily.com/',\n",
       "  'https://docs.tavily.com/api-reference',\n",
       "  'https://docs.tavily.com/api-reference/endpoint/crawl',\n",
       "  'https://docs.tavily.com/api-reference/endpoint/extract',\n",
       "  'https://docs.tavily.com/api-reference/endpoint/search',\n",
       "  'https://docs.tavily.com/documentation/api-reference/endpoint/crawl',\n",
       "  'https://docs.tavily.com/documentation/api-reference/endpoint/extract',\n",
       "  'https://docs.tavily.com/documentation/api-reference/endpoint/map',\n",
       "  'https://docs.tavily.com/documentation/api-reference/endpoint/search',\n",
       "  'https://docs.tavily.com/documentation/api-reference/endpoint/usage',\n",
       "  'https://docs.tavily.com/documentation/api-reference/introduction',\n",
       "  'https://docs.tavily.com/sdk',\n",
       "  'https://docs.tavily.com/sdk/javascript/quick-start',\n",
       "  'https://docs.tavily.com/sdk/javascript/reference',\n",
       "  'https://docs.tavily.com/sdk/python/quick-start',\n",
       "  'https://docs.tavily.com/sdk/python/reference'],\n",
       " 'response_time': 4.11,\n",
       " 'request_id': '03450223-120e-46f6-ae1d-37be55701042'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guided_map_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885758d",
   "metadata": {},
   "source": [
    "### **Conclusion & Next Steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497d4a30",
   "metadata": {},
   "source": [
    "In this tutorial, you learned how to:\n",
    "- Perform real-time web searches using the Tavily API\n",
    "- Extract content from web pages\n",
    "- Crawl and map websites to gather links and information\n",
    "- Guide crawls with the natural language instructions for targeted data extraction\n",
    "\n",
    "These foundational skills enable your agents to access and utilize up-to-date web information, making them more powerful and context-aware. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c821f8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
